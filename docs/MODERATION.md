# Content Moderation Policy

## Our Commitment

DAIRA is committed to creating a safe, inclusive community where diverse voices can be heard. We believe in free expression while maintaining standards that protect users from harm.

## Community Guidelines

### ✅ We Welcome

- **Authentic expression**: Share your real thoughts and experiences
- **Constructive dialogue**: Engage in respectful discussions
- **Creative content**: Original art, music, videos, and writing
- **Diverse perspectives**: Different viewpoints and cultures
- **Support and kindness**: Helping and encouraging others

### ❌ We Don't Allow

#### Prohibited Content

1. **Violence & Dangerous Organizations**
   - Threats of violence
   - Glorification of violence
   - Support for terrorist organizations
   - Instructions for self-harm

2. **Hate Speech**
   - Attacks based on race, ethnicity, religion
   - Dehumanizing language
   - Harmful stereotypes
   - Symbols of hate groups

3. **Harassment & Bullying**
   - Targeted harassment campaigns
   - Doxxing (sharing private information)
   - Stalking or threatening behavior
   - Coordinated abuse

4. **Sexual Content**
   - Non-consensual intimate images
   - Sexual exploitation of minors (zero tolerance)
   - Graphic sexual content
   - Sexual solicitation

5. **Misinformation**
   - Health misinformation causing harm
   - Election interference
   - Manipulated media (deepfakes) without disclosure
   - Coordinated inauthentic behavior

6. **Illegal Activities**
   - Sale of drugs, weapons, or illegal goods
   - Human trafficking
   - Copyright infringement
   - Fraud or scams

7. **Spam & Inauthentic Behavior**
   - Mass unsolicited messages
   - Fake accounts or bots
   - Engagement manipulation
   - Phishing attempts

## Enforcement Actions

### Warning System

**First Warning**: Content removed, education provided
**Second Warning**: Temporary restriction (24-48 hours)
**Third Warning**: Account suspension (7-30 days)
**Severe Violations**: Immediate permanent ban

### Appeal Process

Users can appeal moderation decisions:
1. Submit appeal with explanation
2. Human review within 48 hours
3. Decision communicated with reasoning
4. Final decision after senior review if needed

## Reporting Tools

### How to Report

1. **In-Post Reporting**
   - Tap ⋮ menu on any post
   - Select "Report"
   - Choose violation category
   - Add optional details
   - Submit

2. **Profile Reporting**
   - Visit user profile
   - Tap ⋮ menu
   - Select "Report User"
   - Describe issue

3. **Emergency Reporting**
   - For imminent danger
   - Report to local authorities first
   - Then report via app with "Emergency" flag

### Report Categories

- Hate speech
- Harassment or bullying
- Violence or dangerous organizations
- Spam or misleading
- Sexual content
- Intellectual property violation
- Self-harm or suicide
- Something else

## Content Labels

Instead of removing borderline content, we may add labels:

### Sensitive Content Label
- **Applied to**: Graphic but newsworthy content
- **User experience**: Click-through warning
- **Example**: "This content may be disturbing"

### Disputed Information Label
- **Applied to**: Claims fact-checkers dispute
- **User experience**: Banner with fact-check link
- **Example**: "Independent fact-checkers say this is false"

### Satire/Parody Label
- **Applied to**: Satirical content that might mislead
- **User experience**: "Satire" badge
- **Example**: "This is parody content"

## Automated Moderation

### AI/ML Detection

We use machine learning to detect:
- Explicit images (NSFW classifier)
- Hate speech patterns
- Spam behaviors
- Copied/stolen content

**Note**: All AI decisions can be appealed for human review.

### Hash Matching

We participate in industry initiatives:
- PhotoDNA for child safety
- Hash-sharing for terrorist content
- Copyright fingerprinting systems

## Human Review

### Moderation Team

- **24/7 Coverage**: Around-the-clock human moderators
- **Language Support**: Native speakers for major languages
- **Cultural Context**: Trained on regional nuances
- **Mental Health Support**: Resources for moderators

### Review Process

1. Report received
2. Automated pre-screening
3. Human review within 24 hours
4. Action taken with notification
5. Appeal option provided

## Special Protections

### Minors (Under 18)

- Extra privacy protections
- Restricted DMs from adults
- Age-appropriate content filters
- Parental controls available

### Public Figures

- Higher threshold for criticism
- Context considered for newsworthy content
- Still protected from abuse and threats

### Marginalized Groups

- Extra protections against coordinated harassment
- Faster response to targeted attacks
- Community safety tools

## Room Moderation

### Host Controls

- Mute/unmute participants
- Remove disruptive users
- End room early if needed
- Set room rules

### Real-Time Moderation

- AI monitors for violations
- Human moderators for reported rooms
- Transcripts reviewed for closed rooms

## Transparency Reports

We publish quarterly reports with:
- Total content actioned
- Breakdown by violation type
- Appeal statistics
- False positive rates
- Moderation team metrics

## User Safety Tools

### Blocking

- Block prevents all interactions
- Blocked users can't see your content
- Can be reversed anytime

### Muting

- Mute hides content without notifying user
- Useful for reducing unwanted content
- Doesn't prevent interactions

### Filters

- Keyword filters for comments
- Sensitive content filters
- Customize your experience

### Privacy Controls

- Who can follow you
- Who can message you
- Who can see your posts
- Activity status visibility

## Crisis Resources

If you or someone you know needs help:

### Mental Health
- **Crisis Text Line**: Text HOME to 741741
- **National Suicide Prevention**: 1-800-273-8255
- **International**: befrienders.org

### Abuse & Safety
- **Domestic Violence**: 1-800-799-7233
- **Child Safety**: cybertipline.org
- **LGBTQ+ Support**: thetrevorproject.org

## Updates to This Policy

We review and update these guidelines regularly. Major changes will be announced:
- In-app notification
- Email to users
- Blog post with reasoning

**Last Updated**: January 2024
**Version**: 1.0

## Contact

Questions about moderation?
- Email: moderation@daira.app
- Twitter: @DairaSafety
- Report: safety@daira.app (serious issues)

---

We're building this together. Thank you for helping make DAIRA a safe space for everyone.
